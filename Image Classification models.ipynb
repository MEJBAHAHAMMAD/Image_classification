{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>\n",
    "            <h1> Image Classification models </h1>\n",
    "        </title>\n",
    "        <body>\n",
    "            <p> For Building <b> Image Classification models </b> we will go over the following options: <p><br/>\n",
    "            <li> Training a small network from scratch (as a baseline ) </li>\n",
    "            <li> Using the bottleneck features of a pre-trained network </li>\n",
    "            <li> Fine-tuning the top layers of pre-trained network </li>\n",
    "        </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  \n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <h1><b>Data pre-processing and Data Augmentation<b></h1>      \n",
    "    </head>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  \n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <h1><b> Trainint a small convent from scratch : 80% accuracy </b></h1>\n",
    "    </head>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13496 images belonging to 2 classes.\n",
      "Found 11504 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.7122 - accuracy: 0.5140 - val_loss: 0.6767 - val_accuracy: 0.6325\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 86s 688ms/step - loss: 0.6703 - accuracy: 0.6290 - val_loss: 0.6373 - val_accuracy: 0.6587\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 86s 685ms/step - loss: 0.6356 - accuracy: 0.6365 - val_loss: 0.6162 - val_accuracy: 0.6600\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 86s 691ms/step - loss: 0.6155 - accuracy: 0.6645 - val_loss: 0.6339 - val_accuracy: 0.6438\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 87s 698ms/step - loss: 0.6146 - accuracy: 0.6780 - val_loss: 0.6094 - val_accuracy: 0.6825\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 87s 692ms/step - loss: 0.6209 - accuracy: 0.6835 - val_loss: 0.5375 - val_accuracy: 0.7225\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 86s 692ms/step - loss: 0.6161 - accuracy: 0.6790 - val_loss: 0.5514 - val_accuracy: 0.7013\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 87s 699ms/step - loss: 0.5863 - accuracy: 0.6855 - val_loss: 0.5711 - val_accuracy: 0.6913\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 87s 693ms/step - loss: 0.5866 - accuracy: 0.6965 - val_loss: 0.5222 - val_accuracy: 0.7312\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 87s 692ms/step - loss: 0.5870 - accuracy: 0.6915 - val_loss: 0.5255 - val_accuracy: 0.7387\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 87s 693ms/step - loss: 0.5881 - accuracy: 0.7100 - val_loss: 0.5394 - val_accuracy: 0.7312\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 87s 693ms/step - loss: 0.5806 - accuracy: 0.7100 - val_loss: 0.5009 - val_accuracy: 0.7550\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 87s 695ms/step - loss: 0.5687 - accuracy: 0.7140 - val_loss: 0.5448 - val_accuracy: 0.7100\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 86s 691ms/step - loss: 0.5575 - accuracy: 0.7279 - val_loss: 0.5045 - val_accuracy: 0.7475\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 87s 696ms/step - loss: 0.5465 - accuracy: 0.7315 - val_loss: 0.5194 - val_accuracy: 0.7375\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 87s 698ms/step - loss: 0.5391 - accuracy: 0.7274 - val_loss: 0.5106 - val_accuracy: 0.7513\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 87s 696ms/step - loss: 0.5566 - accuracy: 0.7240 - val_loss: 0.5060 - val_accuracy: 0.7650\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 87s 699ms/step - loss: 0.5457 - accuracy: 0.7425 - val_loss: 0.5434 - val_accuracy: 0.7462\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 87s 694ms/step - loss: 0.5456 - accuracy: 0.7290 - val_loss: 0.5446 - val_accuracy: 0.7462\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 87s 697ms/step - loss: 0.5315 - accuracy: 0.7495 - val_loss: 0.5108 - val_accuracy: 0.7575\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 0.5187 - accuracy: 0.7635 - val_loss: 0.5985 - val_accuracy: 0.7275\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 88s 701ms/step - loss: 0.5135 - accuracy: 0.7735 - val_loss: 0.5142 - val_accuracy: 0.7650\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 88s 706ms/step - loss: 0.5087 - accuracy: 0.7535 - val_loss: 0.4421 - val_accuracy: 0.7962\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 88s 703ms/step - loss: 0.5216 - accuracy: 0.7540 - val_loss: 0.4575 - val_accuracy: 0.7800\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 87s 698ms/step - loss: 0.5088 - accuracy: 0.7615 - val_loss: 0.4981 - val_accuracy: 0.7775\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 87s 698ms/step - loss: 0.4908 - accuracy: 0.7775 - val_loss: 0.4662 - val_accuracy: 0.7812\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 87s 693ms/step - loss: 0.5000 - accuracy: 0.7660 - val_loss: 0.4681 - val_accuracy: 0.7887\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.4976 - accuracy: 0.7800 - val_loss: 0.5110 - val_accuracy: 0.7738\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.5027 - accuracy: 0.7710 - val_loss: 0.4556 - val_accuracy: 0.7975\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 93s 741ms/step - loss: 0.4971 - accuracy: 0.7760 - val_loss: 0.4666 - val_accuracy: 0.8075\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.4942 - accuracy: 0.7760 - val_loss: 0.6966 - val_accuracy: 0.7312\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 87s 694ms/step - loss: 0.4995 - accuracy: 0.7735 - val_loss: 0.4280 - val_accuracy: 0.8138\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 87s 692ms/step - loss: 0.4624 - accuracy: 0.7912 - val_loss: 0.4642 - val_accuracy: 0.7925\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 87s 696ms/step - loss: 0.4985 - accuracy: 0.7720 - val_loss: 0.4462 - val_accuracy: 0.7975\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 87s 699ms/step - loss: 0.4938 - accuracy: 0.7846 - val_loss: 0.4727 - val_accuracy: 0.7987\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 87s 694ms/step - loss: 0.4886 - accuracy: 0.7865 - val_loss: 0.4340 - val_accuracy: 0.8087\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 87s 693ms/step - loss: 0.5135 - accuracy: 0.7715 - val_loss: 0.4767 - val_accuracy: 0.7837\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 87s 692ms/step - loss: 0.4878 - accuracy: 0.7840 - val_loss: 0.4538 - val_accuracy: 0.8112\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 87s 694ms/step - loss: 0.4792 - accuracy: 0.7780 - val_loss: 0.4566 - val_accuracy: 0.7950\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 89s 715ms/step - loss: 0.4618 - accuracy: 0.8030 - val_loss: 0.4495 - val_accuracy: 0.7987\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 87s 698ms/step - loss: 0.4842 - accuracy: 0.7830 - val_loss: 0.4393 - val_accuracy: 0.8000\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 86s 690ms/step - loss: 0.4731 - accuracy: 0.7865 - val_loss: 0.4699 - val_accuracy: 0.7962\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 86s 688ms/step - loss: 0.4707 - accuracy: 0.7875 - val_loss: 0.4351 - val_accuracy: 0.8025\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 86s 688ms/step - loss: 0.4778 - accuracy: 0.7882 - val_loss: 0.4398 - val_accuracy: 0.8087\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 86s 688ms/step - loss: 0.4743 - accuracy: 0.7855 - val_loss: 0.4476 - val_accuracy: 0.7987\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 86s 692ms/step - loss: 0.4645 - accuracy: 0.7925 - val_loss: 0.4579 - val_accuracy: 0.8163\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 86s 689ms/step - loss: 0.4795 - accuracy: 0.7920 - val_loss: 0.4038 - val_accuracy: 0.8313\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 86s 689ms/step - loss: 0.4578 - accuracy: 0.7980 - val_loss: 0.4848 - val_accuracy: 0.7850\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 86s 691ms/step - loss: 0.4455 - accuracy: 0.8160 - val_loss: 0.6434 - val_accuracy: 0.7600\n",
      "Epoch 50/50\n",
      " 38/125 [========>.....................] - ETA: 54s - loss: 0.4518 - accuracy: 0.8010"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "#model = Sequential()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
